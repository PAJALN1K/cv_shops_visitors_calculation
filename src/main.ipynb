{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "56effdbd",
      "metadata": {
        "id": "56effdbd"
      },
      "source": [
        "# Проектная работа: анализ посещаемости магазинов с помощью нейронных сетей в компьютерном зрении"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kyvUM1L5l3yJ",
      "metadata": {
        "id": "kyvUM1L5l3yJ"
      },
      "source": [
        "## 1. Импорт зависимостей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b341a17e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b341a17e",
        "outputId": "fe7b7b03-7484-42f3-cd58-91debde9f2d5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import cv2 as cv\n",
        "import torch\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pNnRjpTdfVfI",
      "metadata": {
        "id": "pNnRjpTdfVfI"
      },
      "source": [
        "## 2. Общие конфигурации и настройки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "OFFhVGk6fVN-",
      "metadata": {
        "id": "OFFhVGk6fVN-"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.random.manual_seed(SEED)\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "LWlm5Jz26wWG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWlm5Jz26wWG",
        "outputId": "d759a0ef-2817-4392-86cd-c7490eca73bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Используемое устройство: cpu\n"
          ]
        }
      ],
      "source": [
        "FORCE_CPU = torch.device(\"cpu\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Используемое устройство: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "saPzLl76l2Ho",
      "metadata": {
        "id": "saPzLl76l2Ho"
      },
      "source": [
        "## 3. Подготовка данных\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02e436e0",
      "metadata": {},
      "source": [
        "### 3.1. Конфигурация и схема данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e55db57b",
      "metadata": {},
      "outputs": [],
      "source": [
        "CUR_DIR = Path.cwd()\n",
        "PROJECT_DIR = CUR_DIR.parent\n",
        "\n",
        "DATA_DIR = PROJECT_DIR / \"data\"\n",
        "INPUT_DATA_DIR = DATA_DIR / \"input\"\n",
        "OUTPUT_DATA_DIR = DATA_DIR / \"output\"\n",
        "MODEL_DIR = PROJECT_DIR / \"models\"\n",
        "\n",
        "for dir in [DATA_DIR, INPUT_DATA_DIR, OUTPUT_DATA_DIR, MODEL_DIR]:\n",
        "    dir.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cbbebec2",
      "metadata": {},
      "outputs": [],
      "source": [
        "VIDEOS_SHAPE = (720, 720)\n",
        "VIDEOS_FPS = 29.0\n",
        "\n",
        "MODEL_INPUT_SHAPE = (640, 640)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "294bf8e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Shop:\n",
        "    def __init__(self, name, pts):\n",
        "        self.name = name\n",
        "        self.pts = np.array(pts)\n",
        "        self.visitors = []\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Shop {self.name} (pts={self.pts})\"\n",
        "    \n",
        "    def clear_visitors(self):\n",
        "        self.visitors.clear()\n",
        "\n",
        "\n",
        "def draw_shop(img, shop):\n",
        "    cv.polylines(img, [shop.pts], isClosed=True, color=(0, 255, 0), thickness=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "iQUhvdDk3wTH",
      "metadata": {
        "id": "iQUhvdDk3wTH"
      },
      "outputs": [],
      "source": [
        "input_videos_filenames = [\n",
        "    INPUT_DATA_DIR / \"input_1.mp4\",\n",
        "    INPUT_DATA_DIR / \"input_2.mp4\",\n",
        "    INPUT_DATA_DIR / \"input_3.mp4\",\n",
        "    INPUT_DATA_DIR / \"input_4.mp4\",\n",
        "]\n",
        "\n",
        "SHOPS_CONFIG_FILE = INPUT_DATA_DIR / \"shops_config.json\"\n",
        "\n",
        "output_videos_filenames = [\n",
        "    OUTPUT_DATA_DIR / \"output_1.mp4\",\n",
        "    OUTPUT_DATA_DIR / \"output_2.mp4\",\n",
        "    OUTPUT_DATA_DIR / \"output_3.mp4\",\n",
        "    OUTPUT_DATA_DIR / \"output_4.mp4\",\n",
        "]\n",
        "\n",
        "output_statistics_filenames = [\n",
        "    OUTPUT_DATA_DIR / \"output_1.json\",\n",
        "    OUTPUT_DATA_DIR / \"output_2.json\",\n",
        "    OUTPUT_DATA_DIR / \"output_3.json\",\n",
        "    OUTPUT_DATA_DIR / \"output_4.json\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4d63248",
      "metadata": {},
      "source": [
        "### 3.2. Экземпляры данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "Q-PPFlRX4Op1",
      "metadata": {
        "id": "Q-PPFlRX4Op1"
      },
      "outputs": [],
      "source": [
        "with open(SHOPS_CONFIG_FILE, \"r\") as file:\n",
        "    shops_configs = json.load(file)\n",
        "\n",
        "shops = [Shop(**shop_cfg) for shop_cfg in shops_configs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11ede870",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Проверка работоспособности и корректности конфигурации\n",
        "\n",
        "ex_idx = 0\n",
        "\n",
        "input_video_filename = input_videos_filenames[ex_idx]\n",
        "\n",
        "cap = cv.VideoCapture(str(input_video_filename))\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"Error opening video file\")\n",
        "else:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    for shop in shops:\n",
        "        draw_shop(frame, shop)\n",
        "    cv.imshow(\"Video Frame\", frame)\n",
        "\n",
        "    cv.waitKey(0)\n",
        "    cap.release()\n",
        "    cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f34aaead",
      "metadata": {},
      "source": [
        "## 4. Нейросетевая модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "63733828",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_FILE = MODEL_DIR / \"yolo11s.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b29cd19e",
      "metadata": {},
      "outputs": [],
      "source": [
        "class PeopleDetectionYOLO:\n",
        "    def __init__(self, model_file=MODEL_FILE, device=FORCE_CPU):\n",
        "        self.model = YOLO(model_file).to(device).eval()\n",
        "\n",
        "    def predict(self, img_tensor):\n",
        "        with torch.no_grad():\n",
        "            return self.model(img_tensor, verbose=False)\n",
        "    \n",
        "    def track(self, frame):\n",
        "        with torch.no_grad():\n",
        "            return self.model.track(frame, persist=True, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "39ee9cc2",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = PeopleDetectionYOLO(device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f86588c",
      "metadata": {},
      "source": [
        "## 5. Подсчёт посетителей на видео"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27a794ce",
      "metadata": {},
      "source": [
        "### 5.1. Методы и структуры данных обработки видео и обнаружения объектов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1d7746ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_frame(frame, new_size=MODEL_INPUT_SHAPE):\n",
        "    frame_resized = cv.resize(frame, new_size)\n",
        "    frame_rgb = cv.cvtColor(frame_resized, cv.COLOR_BGR2RGB)\n",
        "    frame_tensor = torch.tensor(frame_rgb, dtype=torch.float32) / 255.0\n",
        "    preprocessed_frame = frame_tensor.permute(2, 0, 1).unsqueeze(0)\n",
        "    return preprocessed_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4539dec6",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Boxes:\n",
        "    def __init__(self, conf, id, xyxy, xyxyn):\n",
        "        self.conf = conf\n",
        "        self.id = id\n",
        "        self.xyxy = xyxy\n",
        "        self.xyxyn = xyxyn\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Boxes (conf={self.conf}, id={id} xyxyn={self.xyxyn})\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1e0da73c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_boxes(boxes, thresh=0.5):\n",
        "    mask = (boxes.cls == 0) & (boxes.conf > thresh)\n",
        "\n",
        "    filtered_boxes = Boxes(\n",
        "        conf=boxes.conf[mask],\n",
        "        id=boxes.id[mask],\n",
        "        xyxy=boxes.xyxy[mask],\n",
        "        xyxyn=boxes.xyxyn[mask],\n",
        "    )\n",
        "\n",
        "    return filtered_boxes\n",
        "\n",
        "\n",
        "def is_box_inside_polygon(box_xyxy, polygon_points):\n",
        "    x1, y1, x2, y2 = box_xyxy\n",
        "    box = np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])\n",
        "\n",
        "    for point in box:\n",
        "        if not cv.pointPolygonTest(polygon_points, tuple(point), False) >= 0:\n",
        "            return False\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c6efed74",
      "metadata": {},
      "outputs": [],
      "source": [
        "def draw_text(img, x, y, text, color=(0, 0, 255)):\n",
        "    text_size = cv.getTextSize(text, cv.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n",
        "    cv.rectangle(\n",
        "        img,\n",
        "        (x - 1, y - text_size[1] - 2),\n",
        "        (x + text_size[0] + 1, y + 2),\n",
        "        color,\n",
        "        cv.FILLED,\n",
        "    )\n",
        "    text_color = (255, 255, 255) if color == (0, 0, 255) else (0, 0, 0)\n",
        "    cv.putText(img, text, (x, y), cv.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n",
        "\n",
        "\n",
        "def draw_box(img, box_xyxyn, id, conf, color=(0, 0, 255), thickness=1):\n",
        "    h, w, _ = img.shape\n",
        "\n",
        "    x1, y1, x2, y2 = box_xyxyn\n",
        "    x1_abs, y1_abs = int(x1 * w), int(y1 * h)\n",
        "    x2_abs, y2_abs = int(x2 * w), int(y2 * h)\n",
        "\n",
        "    cv.rectangle(\n",
        "        img,\n",
        "        (x1_abs, y1_abs),\n",
        "        (x2_abs, y2_abs),\n",
        "        color,\n",
        "        thickness,\n",
        "    )\n",
        "\n",
        "    draw_text(img, x1_abs + 3, y1_abs + 14, f\"{int(id)}\", color)\n",
        "    draw_text(img, x1_abs + 3, y1_abs + 34, f\"{conf:.2f}\", color)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cab09a8",
      "metadata": {},
      "source": [
        "### 5.2. Запуск процесса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "213d0c1c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# На случай, если нужно будет обновить значения id у boxes\n",
        "# model = PeopleDetectionYOLO(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7043c961",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Уникальных посетителей в Shop 1: 1\n",
            "Уникальных посетителей в Shop 2: 2\n"
          ]
        }
      ],
      "source": [
        "ex_idx = 3\n",
        "thresh = 0.2\n",
        "\n",
        "input_video_filename = input_videos_filenames[ex_idx]\n",
        "output_video_filename = output_videos_filenames[ex_idx]\n",
        "output_statistics_filename = output_statistics_filenames[ex_idx]\n",
        "\n",
        "cap = cv.VideoCapture(str(input_video_filename))\n",
        "fourcc = cv.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv.VideoWriter(str(output_video_filename), fourcc, VIDEOS_FPS, VIDEOS_SHAPE)\n",
        "\n",
        "for shop in shops:\n",
        "    shop.clear_visitors()\n",
        "frame_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    if frame_count % (VIDEOS_FPS // 4) == 0:\n",
        "        frame_tensor = preprocess_frame(frame).to(device)\n",
        "        boxes = model.track(frame)[0].boxes\n",
        "\n",
        "        for shop in shops:\n",
        "            draw_shop(frame, shop)\n",
        "\n",
        "        if boxes and boxes.is_track:\n",
        "            filtered_boxes = filter_boxes(boxes, thresh=thresh)\n",
        "\n",
        "            ids = filtered_boxes.id.numpy()\n",
        "            confs = filtered_boxes.conf.numpy()\n",
        "            xyxys = filtered_boxes.xyxy.numpy()\n",
        "            xyxyns = filtered_boxes.xyxyn.numpy()\n",
        "\n",
        "            for id, conf, xyxy, xyxyn in zip(ids, confs, xyxys, xyxyns):\n",
        "                draw_box(frame, xyxyn, id, conf)\n",
        "\n",
        "                for shop in shops:\n",
        "                    if is_box_inside_polygon(xyxy, shop.pts):\n",
        "                        shop.visitors.append(id)\n",
        "                        draw_box(frame, xyxyn, id, conf, (0, 255, 255))\n",
        "\n",
        "            for shop in shops:\n",
        "                visitor_count = len(set(shop.visitors))\n",
        "                text_position = (\n",
        "                    shop.pts[0][0],\n",
        "                    shop.pts[0][1] - 10,\n",
        "                )\n",
        "\n",
        "                draw_text(\n",
        "                    frame,\n",
        "                    text_position[0],\n",
        "                    text_position[1],\n",
        "                    f\"{shop.name}: {visitor_count}\",\n",
        "                    (0, 255, 0),\n",
        "                )\n",
        "\n",
        "        out.write(frame)\n",
        "        cv.imshow(\"YOLO\", frame)\n",
        "\n",
        "        if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "output_statistics = []\n",
        "for shop in shops:\n",
        "    visitor_count = len(set(shop.visitors))\n",
        "\n",
        "    print(f\"Уникальных посетителей в {shop.name}: {visitor_count}\")\n",
        "    \n",
        "    output_statistics.append(dict(name=shop.name, visitor_count=visitor_count))\n",
        "    \n",
        "with open(output_statistics_filename, \"w\", encoding=\"utf-8\") as json_file:\n",
        "    json.dump(\n",
        "        output_statistics,\n",
        "        json_file,\n",
        "        ensure_ascii=False,\n",
        "        indent=4,\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
